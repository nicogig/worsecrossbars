{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# MNIST Multilayer Perceptron",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00000-addc4bff-8829-472b-9a79-090b3cf692ee",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Code setup",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00001-36dfdd49-ebee-404b-8770-594e30e77101",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-ba20633c-d19e-4bcb-81f0-848ec9d6a22e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bd819384",
    "execution_start": 1631558494332,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "# Suppressing warnings\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-5766e560-aa1a-4680-b9a8-f64aa8cdd61d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2ee921d4",
    "execution_start": 1631558494339,
    "execution_millis": 6074,
    "deepnote_cell_type": "code"
   },
   "source": "# Utility imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nfrom pathlib import Path\nimport gc\nimport pickle\n\n# Source imports\nfrom mlp_generator import one_layer, two_layers, three_layers, four_layers\nfrom mlp_trainer import dataset_creation, train_MLP\nfrom fault_simulation import run_simulation",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-42d3d6b2-bfcd-43a4-abae-e592235242a4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ecd17367",
    "execution_start": 1631558500418,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "# The statements below are employed to control the mode in which the Jupyter\n# notebook operates.\n\n# Legal values: [1, 2, 3, 4]\nnumber_of_hidden_layers = 1\n\n# Legal values: [1, 2, 3]; 1: Cannot electroform, 2: Stuck at HRS, 3: Stuck at LRS\nfault_type = 2\n\n# Device parameters\nHRS_LRS_ratio = 5\nexcluded_weights_proportion = 0.015",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Neural network setup and training",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00003-ab4c891d-eb7c-4ff4-8720-15330b11cb91",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-563afe49-4c80-49bf-b8a8-cf906b9aa0c2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a5fe9380",
    "execution_start": 1631558500425,
    "execution_millis": 583,
    "deepnote_cell_type": "code"
   },
   "source": "# Create dataset and results lists\nMNIST_dataset = dataset_creation()\nweights_list = []\nhistories_list = []\n\n# Helper values\ngenerator_functions = {1: one_layer, 2:two_layers, 3:three_layers, 4:four_layers}\nnumber_of_ANNs = 5",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-203f487f-eb74-4711-af41-841cbe7610df",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9aa6d631",
    "execution_start": 1631558501013,
    "execution_millis": 63403,
    "deepnote_cell_type": "code"
   },
   "source": "# Model definition and training, repeated 30 times to average out stochastic variancies\nfor model_number in range(0, number_of_ANNs):\n\n    MNIST_MLP = generator_functions[number_of_hidden_layers]()\n    MLP_weights, MLP_history, *_ = train_MLP(MNIST_dataset, MNIST_MLP, epochs=10, batch_size=100)\n    weights_list.append(MLP_weights)\n    histories_list.append(MLP_history)\n    \n    if (model_number+1) % 5 == 0 and model_number != 0:\n        print(\"Model #{} finished training.\".format(model_number+1))\n    \n    gc.collect()",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "Model #5 finished training.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Performance evolution during training",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00009-eddf23c5-2e67-44a2-9349-b7cdaeab4ee1",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-c2fd90e0-a7ce-4883-831e-719792af7b78",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5dd66cfa",
    "execution_start": 1631558564417,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "# Computing training and validation loss and accuracy by averaging over all the models trained in the previous step\n\nepochs = range(1, len(histories_list[0].history[\"accuracy\"]) + 1)\naccuracy_values = np.zeros(len(histories_list[0].history[\"accuracy\"]))\nvalidation_accuracy_values = np.zeros(len(histories_list[0].history[\"accuracy\"]))\nloss_values = np.zeros(len(histories_list[0].history[\"accuracy\"]))\nvalidation_loss_values = np.zeros(len(histories_list[0].history[\"accuracy\"]))\n\nfor MLP_history in histories_list:\n\n    history_dict = MLP_history.history\n    accuracy_values += np.array(history_dict[\"accuracy\"])\n    validation_accuracy_values += np.array(history_dict[\"val_accuracy\"])\n    loss_values += np.array(history_dict[\"loss\"])\n    validation_loss_values += np.array(history_dict[\"val_loss\"])\n\naccuracy_values /= len(histories_list)\nvalidation_accuracy_values /= len(histories_list)\nloss_values /= len(histories_list)\nvalidation_loss_values /= len(histories_list)",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-b71f2679-3e1f-49dc-b44a-c00795a0f5c9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "807e6716",
    "execution_start": 1631558564418,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "# Saving training/validation data to file\npickle.dump((accuracy_values, validation_accuracy_values, loss_values, validation_loss_values), open(\"saved_data/training_validation_{}HL.p\".format(number_of_hidden_layers), \"wb\"))",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Fault simulation: Cannot electroform, Stuck at HRS, Stuck at LRS",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00011-d84d9894-5d86-4ed5-b1aa-1494658c9899",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-fe2aa972-dedc-4121-ab29-e0a6189f3828",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "41eef98d",
    "execution_start": 1631558564420,
    "execution_millis": 38,
    "deepnote_cell_type": "code"
   },
   "source": "# # Setting variable percentages of the ANN's synaptic weights to zero in order to simulate devices being unable to electroform\n\n# percentages = np.arange(0, 1.01, 0.01)\n# accuracies = np.zeros(len(percentages))\n\n# MNIST_MLP = generator_functions[number_of_hidden_layers]()\n# MNIST_MLP.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# for count, weights in enumerate(weights_list):\n\n#     accuracies_list = []\n\n#     for percentage in percentages:\n        \n#         altered_weights = alteration_functions[fault_type](weights, percentage)\n        \n#         # The \"set_weights\" function sets the ANN's weights to the values specified in the list of arrays \"altered_weights\"\n#         MNIST_MLP.set_weights(altered_weights)\n#         accuracies_list.append(MNIST_MLP.evaluate(MNIST_dataset[1][0], MNIST_dataset[1][1], verbose=0)[1])\n\n#     accuracies += np.array(accuracies_list)\n\n#     if (count+1) % 5 == 0 and count != 0:\n#         print(\"Finished evaluating weight set #{}.\".format(count+1))\n    \n#     gc.collect()\n\n# accuracies /= len(weights_list)\n\n# # Saving accuracies array to file\n# pickle.dump((percentages, accuracies, fault_type), open(\"saved_data/accuracies_faultType{}_{}HL.p\".format(fault_type, number_of_hidden_layers), \"wb\"))",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-da8ce3f7-47d4-4ccf-b728-840b1d853df0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "57828f31",
    "execution_start": 1631558564459,
    "execution_millis": 788890,
    "deepnote_cell_type": "code"
   },
   "source": "# Running 30 simulations for each of the 30 networks trained above over the specified\n# range of faulty devices percentages\n\nMNIST_MLP = generator_functions[number_of_hidden_layers]()\nMNIST_MLP.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\npercentages = np.arange(0, 1.01, 0.01)\naccuracies_array = np.zeros((len(weights_list), len(percentages)))\n\nnumber_of_simulations = 5\n\nfor count, weights in enumerate(weights_list):\n\n    accuracies_array[count] = run_simulation(percentages, weights, number_of_simulations, MNIST_MLP, MNIST_dataset, fault_type, HRS_LRS_ratio, excluded_weights_proportion)\n    gc.collect()\n\n    if (count+1) % 5 == 0 and count != 0:\n        print(\"Finished evaluating weight set #{}.\".format(count+1))\n\n#Â Averaging the results obtained for each of the 30 sets of weights\naccuracies = np.mean(accuracies_array, axis=0, dtype=np.float64)\n\n# Saving accuracies array to file\npickle.dump((percentages, accuracies, fault_type), open(\"saved_data/accuracies_faultType{}_{}HL.p\".format(fault_type, number_of_hidden_layers), \"wb\"))",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "Finished evaluating weight set #5.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f63981ff-15e3-4a0a-8bcf-dbdeefafcfde' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "4616b1a2-d934-4bd9-98ed-d3b8a17287f5",
  "deepnote_execution_queue": []
 }
}